{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcbc1c93-019e-41c0-9d42-a15d38d0e991",
   "metadata": {},
   "source": [
    "# Deploy UL2 model on GPUs with NVIDIA Triton using NVIDIA's FasterTransformers backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204e1e7d-59d9-47ce-8340-7fa707cc7451",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a695ea4-950d-4b2f-9059-54ca0022cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "import os\n",
    "\n",
    "# Get your Google Cloud project ID using google.auth\n",
    "import google.auth\n",
    "\n",
    "_, PROJECT_ID = google.auth.default()\n",
    "print(\"Project ID: \", PROJECT_ID)\n",
    "\n",
    "# validate PROJECT_ID\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    print(\n",
    "        f\"Please set your project id before proceeding to next step. Currently it's set as {PROJECT_ID}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12e197-18a7-41d1-a003-7d36f77806f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2c838-ed5e-4656-85e2-8785b5c0889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caad556-9912-460c-98ac-294f078f4c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_NAME = \"gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99be043-d756-4ed0-b27d-9c15c9ab44c6",
   "metadata": {},
   "source": [
    "## Setting up Artifact Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401c983-4df9-41a0-a7da-15298eebac72",
   "metadata": {},
   "source": [
    "- Enable the Artifact Registry API service for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f3ca7-4855-4210-9490-89f76585bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e23d5-b482-4d46-9888-c7a803def8a6",
   "metadata": {},
   "source": [
    "- Create a private Docker repository to push the container images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3ec78-8ec6-4fd8-9226-090d0447e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKER_ARTIFACT_REPO = \"llms-on-vertex-ai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8642d-ff9f-493e-a8d0-ad87d2d94b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Docker repository with your region with the description\n",
    "! gcloud artifacts repositories create {DOCKER_ARTIFACT_REPO} \\\n",
    "    --repository-format=docker \\\n",
    "    --location={REGION} \\\n",
    "    --description=\"Triton Docker repository\"\n",
    "\n",
    "# verify that your repository was created.\n",
    "! gcloud artifacts repositories list \\\n",
    "    --location={REGION} \\\n",
    "    --filter=\"name~\"{DOCKER_ARTIFACT_REPO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fb29c-ee82-474a-ac64-16c72130cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e48fd6-ffc9-43dc-aef0-0c02c8506707",
   "metadata": {},
   "source": [
    "- Configure authentication to the private repo\n",
    "\n",
    "Before you push or pull container images, configure Docker to use the gcloud command-line tool to authenticate requests to Artifact Registry for your region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140aafa-de61-4092-856e-2df29d8bd84b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convert JAX Checkpoint to FasterTransformers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b34f2-410a-4c88-bd53-3d499311195f",
   "metadata": {},
   "source": [
    "- [ ] Conversion steps\n",
    "    - [ ] Download JAX checkpoint from GCS\n",
    "    - [ ] Run conversion script to convert from JAX to FT\n",
    "    - [ ] Validate conversion is running fine\n",
    "    - [ ] Organize model repository as Triton's spec\n",
    "    - [ ] Upload FT checkpoint to GCS\n",
    "- [ ] Build container image to run conversion\n",
    "    - [ ] Prepare docker\n",
    "- [ ] Configure infra to run conversion\n",
    "    - [ ] Pick Compute choice: GCE, Vertex AI Training Custom Job, GKE, Cloud Batch\n",
    "    - [ ] Configure compute spec\n",
    "- [ ] Run conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663faab-099c-4a1c-be4f-a3c46753d9b0",
   "metadata": {},
   "source": [
    "### JAX --> FT Conversion Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aaa77f-c86f-46e6-b821-9e4512e0d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/run-converter-jax-to-fastertransformer.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# gcs_jax_checkpoint_location\n",
    "# gcs_ft_checkpoint_location\n",
    "# tensor-parallelism (1,2,4,8)\n",
    "\n",
    "# Set up a global error handler\n",
    "err_handler() {\n",
    "    echo \"Error on line: $1\"\n",
    "    echo \"Caused by: $2\"\n",
    "    echo \"That returned exit status: $3\"\n",
    "    echo \"Aborting...\"\n",
    "    exit $3\n",
    "}\n",
    "\n",
    "trap 'err_handler \"$LINENO\" \"$BASH_COMMAND\" \"$?\"' ERR\n",
    "\n",
    "TIMESTAMP=`date \"+%Y-%m-%d %H:%M:%S\"`\n",
    "\n",
    "echo \"NVIDIA Driver version\"\n",
    "nvidia-smi\n",
    "\n",
    "# Set variables\n",
    "GCS_JAX_CHECKPOINT=$1\n",
    "echo \"GCS_JAX_CHECKPOINT = ${GCS_JAX_CHECKPOINT}\"\n",
    "\n",
    "GCS_FT_CHECKPOINT=$2\n",
    "echo \"GCS_FT_CHECKPOINT = ${GCS_FT_CHECKPOINT}\"\n",
    "\n",
    "if [[ -z $3 ]];\n",
    "then \n",
    "    TENSOR_PARALLELISM=1\n",
    "else\n",
    "    TENSOR_PARALLELISM=$3\n",
    "fi\n",
    "echo \"TENSOR_PARALLELISM = ${TENSOR_PARALLELISM}\"\n",
    "\n",
    "# Copy JAX checkpoint to local directory\n",
    "LOCAL_JAX_CHECKPOINT=\"/models/\"$(basename $GCS_JAX_CHECKPOINT)\n",
    "mkdir -p $LOCAL_JAX_CHECKPOINT\n",
    "echo \"[INFO] ${TIMESTAMP} Copying JAX checkpoint from ${GCS_JAX_CHECKPOINT} to local ${LOCAL_JAX_CHECKPOINT}\"\n",
    "SECONDS=0\n",
    "gcloud storage cp --quiet --recursive $GCS_JAX_CHECKPOINT /models/\n",
    "echo \"[INFO] Completed copying JAX checkpoint locally in ${SECONDS}s\"\n",
    "\n",
    "# Creating local directories for saving FasterTransformer model\n",
    "LOCAL_FT_CHECKPOINT=\"/models/ul2-ft\"\n",
    "mkdir -p $LOCAL_FT_CHECKPOINT\n",
    "\n",
    "# Run JAX to FasterTransformer \n",
    "echo \"[INFO] ${TIMESTAMP} Converting JAX checkpoint to FasterTransformer\"\n",
    "SECONDS=0\n",
    "cd /FasterTransformer/build && \\\n",
    "   python3 ../examples/pytorch/t5/utils/jax_t5_ckpt_convert.py \\\n",
    "   $LOCAL_JAX_CHECKPOINT \\\n",
    "   $LOCAL_FT_CHECKPOINT \\\n",
    "   --tensor-parallelism $TENSOR_PARALLELISM\n",
    "echo \"[INFO] ${TIMESTAMP} Completed converting JAX checkpoint to FasterTransformer in ${SECONDS}s\"\n",
    "\n",
    "# Organize model repository for Triton serving\n",
    "echo \"[INFO] ${TIMESTAMP} Organizing model repository for serving\"\n",
    "cd $LOCAL_FT_CHECKPOINT\n",
    "mkdir -p $LOCAL_FT_CHECKPOINT/ul2/1\n",
    "mv $LOCAL_FT_CHECKPOINT/1-gpu $LOCAL_FT_CHECKPOINT/ul2/1/\n",
    "\n",
    "# Format Triton config for UL2\n",
    "cp /triton/config.pbtxt $LOCAL_FT_CHECKPOINT/ul2/config.pbtxt\n",
    "sed -i -e 's!@@MODEL_CHECKPOINT_PATH@@!'$GCS_FT_CHECKPOINT'ul2/1/1-gpu!g' $LOCAL_FT_CHECKPOINT/ul2/config.pbtxt \n",
    "sed -i -e 's!@@TENSOR_PARA_SIZE@@!'$TENSOR_PARALLELISM'!g' $LOCAL_FT_CHECKPOINT/ul2/config.pbtxt \n",
    "sed -i -e 's!@@PIPELINE_PARA_SIZE@@!'$TENSOR_PARALLELISM'!g;' $LOCAL_FT_CHECKPOINT/ul2/config.pbtxt \n",
    "\n",
    "# Uploaded FasterTransformer checkpoint to Cloud Storage bucket\n",
    "echo \"[INFO] ${TIMESTAMP} Copying FasterTransformer model from local ${LOCAL_FT_CHECKPOINT} to ${GCS_FT_CHECKPOINT}\"\n",
    "SECONDS=0\n",
    "gcloud storage cp --recursive $LOCAL_FT_CHECKPOINT $GCS_FT_CHECKPOINT -q\n",
    "echo \"[INFO] Completed copying FasterTransformer model to Cloud Storage in ${SECONDS}s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde77762-e4df-4860-a74f-1c86a5bfb75d",
   "metadata": {},
   "source": [
    "### Build container image to run conversion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8ed79-c23c-4442-88ed-6c5aca242ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/Dockerfile.jax-to-fastertransformer\n",
    "\n",
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "FROM nvcr.io/nvidia/pytorch:22.07-py3\n",
    "\n",
    "# Install gcloud SDK\n",
    "RUN apt-get install apt-transport-https ca-certificates gnupg\n",
    "RUN echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg  add - && apt-get update -y && apt-get install google-cloud-cli -y\n",
    "\n",
    "# Clone FasterTransformer repo\n",
    "WORKDIR /\n",
    "RUN git clone --branch=main https://github.com/NVIDIA/FasterTransformer.git\n",
    "\n",
    "# Build FasterTransformer\n",
    "# Specify SM version as 80 for A100 GPUs; and 70 for V100\n",
    "WORKDIR /FasterTransformer\n",
    "RUN mkdir build && \\\n",
    "    cd build && \\\n",
    "    cmake -DSM=80 -DCMAKE_BUILD_TYPE=Release -DBUILD_PYT=ON -DBUILD_MULTI_GPU=ON .. && \\\n",
    "    make -j12\n",
    "\n",
    "# Install other required packages\n",
    "WORKDIR /FasterTransformer\n",
    "RUN pip install -r /FasterTransformer/examples/pytorch/t5/requirement.txt\n",
    "RUN pip install transformers==4.20.1 zarr\n",
    "RUN pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "\n",
    "# Copy conversion script\n",
    "COPY ul2-inference/converter/jax_t5_ckpt_convert.py ul2-inference/converter/ul2_config.template /FasterTransformer/examples/pytorch/t5/utils/\n",
    "COPY run-converter-jax-to-fastertransformer.sh /run-converter-jax-to-fastertransformer.sh\n",
    "\n",
    "# Copy Triton related config\n",
    "RUN mkdir -p /triton\n",
    "COPY ul2-inference/triton/config.pbtxt /triton/config.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f14d3b-1c47-4e1c-8758-4126c195bb7a",
   "metadata": {},
   "source": [
    "- Build the image and tag the Artifact Registry path that the image will be pushed to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae51eb2-363b-4871-91c3-d7b698d55125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX to FasterTransformers container image name\n",
    "JAX_TO_FT_IMAGE_NAME = \"jax-to-fastertransformer\"\n",
    "# JAX_TO_FT_IMAGE_URI = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{DOCKER_ARTIFACT_REPO}/{JAX_TO_FT_IMAGE_NAME}\"\n",
    "JAX_TO_FT_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{DOCKER_ARTIFACT_REPO}/{JAX_TO_FT_IMAGE_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168bf6c-00e4-4236-9820-967c918c990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "JAX_TO_FT_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bf65d-975e-4a8f-bae0-b0953277d491",
   "metadata": {},
   "source": [
    "- Create Cloud Build configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109e5d6-834d-4c13-8991-f590b81bb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/cloudbuild.yaml\n",
    "\n",
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: ['build', '-t', '$_IMAGE_URI', '$_FILE_LOCATION', '-f', '$_FILE_LOCATION/Dockerfile.$_DOCKERNAME']\n",
    "images:\n",
    "- '$_IMAGE_URI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6defa421-b883-4ff5-b922-26d2d4d61a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -ltr ./src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a6516-6296-4e28-b4af-9d69e54eae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOCATION = './src'\n",
    "! gcloud builds submit \\\n",
    "      --region $REGION \\\n",
    "      --config src/cloudbuild.yaml \\\n",
    "      --substitutions _DOCKERNAME=$JAX_TO_FT_IMAGE_NAME,_IMAGE_URI=$JAX_TO_FT_IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "      --timeout \"2h\" \\\n",
    "      --machine-type=e2-highcpu-32 \\\n",
    "      --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780831a2-2328-41f2-9b17-c3976e27e16a",
   "metadata": {},
   "source": [
    "- Use local docker to build and push the container image to Artifact Registry. The Artifact Registry image URI will be used when creating the Vertex AI model resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6dd268-e4d1-455e-b8f1-809c6d0e1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! docker build -t $JAX_TO_FT_IMAGE_URI . -f Dockerfile.jax-to-fastertransformer\n",
    "# ! docker push $JAX_TO_FT_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b7f4c-96f8-42c4-8983-6ae32277e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run script from docker on a GCE machine\n",
    "# docker run -ti \\\n",
    "#   --gpus all \\\n",
    "#   --shm-size 5g \\\n",
    "#   -p 9999:9999 \\\n",
    "#   -v $PWD:$PWD \\\n",
    "#   -v /home/jupyter/models:/models \\\n",
    "#   -w $PWD \\\n",
    "#   --name ft-converter \\\n",
    "#   us-central1-docker.pkg.dev/rthallam-demo-project/llms-on-vertex-ai/jax-to-fastertransformer \\\n",
    "#   bash\n",
    "#  /run-converter-jax-to-fastertransformer.sh \\\n",
    "#    \"gs://se-checkpoints/ul2-xsum\" \\\n",
    "#    \"gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77/llm/models/ul2/ft/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727633d-3b77-4014-9106-d32beb5079b2",
   "metadata": {},
   "source": [
    "### Configure Vertex AI Training CustomJob  to run JAX --> FT conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2273a4d-21ed-4d6e-a93b-c7b7852abb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $BUCKET_NAME $JAX_TO_FT_IMAGE_URI\n",
    "\n",
    "BUCKET_NAME=$1\n",
    "JAX_TO_FT_IMAGE_URI=$2\n",
    "\n",
    "cat << EOF > ./src/config.jax-to-fastertransformer.yaml\n",
    "\n",
    "baseOutputDirectory:\n",
    "    outputUriPrefix: ${BUCKET_NAME}/llm/jobs/ul2-jax-to-f/$(date \"+%Y%m%d-%H%M%S\")/\n",
    "workerPoolSpecs:\n",
    "  -\n",
    "    machineSpec:\n",
    "      machineType: a2-highgpu-1g \n",
    "      acceleratorType: NVIDIA_TESLA_A100\n",
    "      acceleratorCount: 1\n",
    "    replicaCount: 1\n",
    "    diskSpec:\n",
    "      bootDiskType: pd-ssd\n",
    "      bootDiskSizeGb: 500\n",
    "    containerSpec:\n",
    "      imageUri: ${JAX_TO_FT_IMAGE_URI}\n",
    "      command:\n",
    "      - /run-converter-jax-to-fastertransformer.sh\n",
    "      args:\n",
    "      - \"gs://se-checkpoints/ul2-xsum\"\n",
    "      - \"gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77/llm/models/ul2/ft/\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3588b-0277-4318-922e-29113e27066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $BUCKET_NAME $JAX_TO_FT_IMAGE_URI\n",
    "\n",
    "BUCKET_NAME=$1\n",
    "JAX_TO_FT_IMAGE_URI=$2\n",
    "\n",
    "cat << EOF > ./src/config.jax-to-fastertransformer.yaml\n",
    "\n",
    "baseOutputDirectory:\n",
    "    outputUriPrefix: ${BUCKET_NAME}/llm/jobs/ul2-jax-to-f/$(date \"+%Y%m%d-%H%M%S\")/\n",
    "workerPoolSpecs:\n",
    "  -\n",
    "    machineSpec:\n",
    "      machineType: a2-highgpu-1g \n",
    "      acceleratorType: NVIDIA_TESLA_A100\n",
    "      acceleratorCount: 1\n",
    "    replicaCount: 1\n",
    "    diskSpec:\n",
    "      bootDiskType: pd-ssd\n",
    "      bootDiskSizeGb: 500\n",
    "    containerSpec:\n",
    "      imageUri: ${JAX_TO_FT_IMAGE_URI}\n",
    "      command:\n",
    "      - /bin/bash\n",
    "      - /run-converter-jax-to-fastertransformer.sh\n",
    "      - \"gs://se-checkpoints/ul2-xsum\"\n",
    "      - \"gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77/llm/models/ul2/ft/\"\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b5c65-d959-4744-92a8-821ead9232e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat ./src/config.jax-to-fastertransformer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f1cd9-245c-4980-9990-2721658ba201",
   "metadata": {},
   "source": [
    "### Run conversion on Vertex AI Training CustomJOb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43874b-762f-4ebf-b65d-ab0b33b12b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud beta ai custom-jobs create \\\n",
    "  --display-name=llm-ul2-jax-to-ft-conversion \\\n",
    "  --region=$REGION \\\n",
    "  --project=$PROJECT_ID \\\n",
    "  --config=./src/config.jax-to-fastertransformer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3591a-4654-48af-9e80-5b1fb4dba6d7",
   "metadata": {},
   "source": [
    "## Deploying FasterTransformer Checkpoint on Vertex AI Prediction Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b68436-064e-4bfc-af05-393f9d6101f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a1c8b-bf03-4389-8540-9c9f845edc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b9796-eb03-44ae-92de-00d8ffb6a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARTIFACTS_REPOSITORY = f\"{BUCKET_NAME}/llm/models/ul2/ft/ul2-ft\"\n",
    "\n",
    "MODEL_NAME = \"llms-ul2-xsum-inference\"\n",
    "MODEL_DISPLAY_NAME = f\"triton-{MODEL_NAME}\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"endpoint-{MODEL_NAME}\"\n",
    "\n",
    "# requires allow listing\n",
    "NGC_TRITON_IMAGE_URI = \"nvcr.io/ea-bignlp/bignlp-inference:22.08-py3\"\n",
    "\n",
    "# prediction container image name\n",
    "IMAGE_NAME = \"nemo-bignlp-triton-inference\"\n",
    "IMAGE_URI = f\"gcr.io/{PROJECT_ID}/llms-on-vertex-ai/{IMAGE_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693b4de-914e-416c-8ec9-607736521af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MODEL_DISPLAY_NAME = {MODEL_DISPLAY_NAME}\")\n",
    "print(f\"IMAGE_URI = {IMAGE_URI}\")\n",
    "print(f\"MODEL_ARTIFACTS_REPOSITORY = {MODEL_ARTIFACTS_REPOSITORY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c6992d-bca0-4b36-88fc-7d645fb20f8a",
   "metadata": {},
   "source": [
    "- Upload model FT checkpoint to Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc06a6b-83cc-4f41-83f4-80ec20f07fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_MODEL = 'projects/560224572293/locations/us-central1/models/1999664205250166784@1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da99e18-c4ac-44f0-8607-0e74ecb1572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aip.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    "    # artifact_uri=MODEL_ARTIFACTS_REPOSITORY,\n",
    "    parent_model=PARENT_MODEL,\n",
    "    sync=True,\n",
    "    serving_container_args=[\n",
    "        f'--model-repository={MODEL_ARTIFACTS_REPOSITORY}',\n",
    "        '--strict-model-config=true',\n",
    "        '--log-verbose=99',\n",
    "        '--log-error=1']\n",
    ")\n",
    "\n",
    "model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cefff8-0b7e-4423-8a4c-d895f33e18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aip.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95f838-3ee1-49f9-b429-252d03cc9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aip.Model('projects/560224572293/locations/us-central1/models/1999664205250166784@2')\n",
    "endpoint = aip.Endpoint('projects/560224572293/locations/us-central1/endpoints/5911401121435353088')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f7a78-8ef6-4363-9e53-6d1aecea8cfa",
   "metadata": {},
   "source": [
    "- Create [custom service account](https://cloud.google.com/vertex-ai/docs/general/custom-service-account) to access model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dcde25-046f-48af-9d72-2500562c33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud iam service-accounts list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a86a1-c8bc-4a0f-a282-f41721f8315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create role\n",
    "! gcloud iam roles create storage_buckets_viewer \\\n",
    "    --project=$PROJECT_ID \\\n",
    "    --title=\"storage.buckets.get\" \\\n",
    "    --description=\"Storage object reader\" \\\n",
    "    --permissions=\"storage.buckets.get\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d6ad3-817a-40a1-a071-786acb0de3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_SA_NAME=\"vertex-ai-llm-sa\"\n",
    "\n",
    "! gcloud iam service-accounts create $CUSTOM_SA_NAME \\\n",
    "    --description=\"Custom service account to attach to Vertex AI resources used for LLMs\" \\\n",
    "    --display-name=$CUSTOM_SA_NAME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58b563-39b0-4747-8672-af0dc6f4eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=\"serviceAccount:\"$CUSTOM_SA_NAME\"@\"$PROJECT_ID\".iam.gserviceaccount.com\" \\\n",
    "    --role=\"projects/\"$PROJECT_ID\"/roles/storage_buckets_viewer\" \\\n",
    "    --condition=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d786a98-b160-48bd-b08b-29757f1ceead",
   "metadata": {},
   "outputs": [],
   "source": [
    "! set -x && PROJECT_NUMBER=$(gcloud projects list \\\n",
    "--filter=\"$(gcloud config get-value project)\" \\\n",
    "--format=\"value(PROJECT_NUMBER)\") && echo $PROJECT_NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f7ac3-56c4-42e5-bce5-0371facd0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "! set -x && \\\n",
    "  CUSTOM_SA_NAME=\"vertex-ai-llm-sa@rthallam-demo-project.iam.gserviceaccount.com\" && \\\n",
    "  PROJECT_NUMBER=$(gcloud projects list \\\n",
    "    --filter=\"$(gcloud config get-value project)\" \\\n",
    "    --format=\"value(PROJECT_NUMBER)\") && \\\n",
    "  AI_PLATFORM_SERVICE_AGENT=\"service-\"$PROJECT_NUMBER\"@gcp-sa-aiplatform.iam.gserviceaccount.com\" && \\\n",
    "  gcloud iam service-accounts add-iam-policy-binding $CUSTOM_SA_NAME \\\n",
    "    --role=roles/iam.serviceAccountAdmin \\\n",
    "    --member=\"serviceAccount:\"$AI_PLATFORM_SERVICE_AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923e409-9d52-4a03-85f9-0cfecc23be53",
   "metadata": {},
   "source": [
    "- Deploy model to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec208502-812f-45eb-a454-93970fc80b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "! export REGION=us-central1 && \\\n",
    "  export MODEL_DISPLAY_NAME=\"triton-llms-ul2-xsum-inference\" && \\\n",
    "  export ENDPOINT_ID=5911401121435353088 && \\\n",
    "  export MODEL_ID=1999664205250166784 && \\\n",
    "  CUSTOM_SA_NAME=\"vertex-ai-llm-sa@rthallam-demo-project.iam.gserviceaccount.com\" && \\\n",
    "  set -x && \\\n",
    "  gcloud alpha ai endpoints deploy-model $ENDPOINT_ID \\\n",
    "    --region=$REGION \\\n",
    "    --model=$MODEL_ID \\\n",
    "    --display-name=$MODEL_DISPLAY_NAME \\\n",
    "    --machine-type=a2-highgpu-1g \\\n",
    "    --accelerator=count=1,type=nvidia-tesla-a100 \\\n",
    "    --enable-access-logging \\\n",
    "    --enable-container-logging \\\n",
    "    --service-account=$CUSTOM_SA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e6010-6f55-499f-af9d-39d85287e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"a2-highgpu-1g\"\n",
    "accelerator_type = \"NVIDIA_TESLA_A100\"\n",
    "accelerator_count = 1\n",
    "min_replica_count = 1\n",
    "max_replica_count = 2\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "    machine_type=machine_type,\n",
    "    min_replica_count=min_replica_count,\n",
    "    max_replica_count=max_replica_count,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "endpoint.name"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "t5x-base",
   "name": "common-cu110.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m93"
  },
  "kernelspec": {
   "display_name": "t5x-base",
   "language": "python",
   "name": "t5x-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
